{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyannote/pyannote-audio/blob/develop/tutorials/intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOWusGNiFdLN"
      },
      "source": [
        "# Introduction to `pyannote.audio`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fs2d8otYnp7"
      },
      "source": [
        "[`pyannote.audio`](https://github.com/pyannote/pyannote-audio) is an open-source Python toolkit for **speaker diarization** — the task of determining *“who speaks when”* by partitioning an audio conversation into speaker-specific time segments.  \n",
        "\n",
        "Based on the [`PyTorch`](https://pytorch.org) machine learning framework, it offers a collection of trainable, end-to-end neural building blocks. These components can be combined and jointly optimized to create powerful speaker diarization pipelines.  \n",
        "\n",
        "In addition, `pyannote.audio` provides pretrained [models](https://huggingface.co/models?other=pyannote-audio-model) and [pipelines](https://huggingface.co/models?other=pyannote-audio-pipeline) for a wide range of tasks such as voice activity detection, speaker segmentation, overlapped speech detection, and speaker embedding — many of which achieve state-of-the-art performance.  \n",
        "\n",
        "**This notebook will show you how to apply these pretrained pipelines to your own audio data.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tckHJKZnYnp7"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai082p4HYnp7"
      },
      "outputs": [],
      "source": [
        "# Install pyannote.audio and ipyannote\n",
        "!pip install -qq pyannote.audio==4.0.3 ipyannote==0.2.0\n",
        "# Google Colab only: ensure torchvision and ipython version are setup correctly\n",
        "!pip install -qq torchvision==0.23.0 ipython==7.34.0\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIzuCWUzFPHU"
      },
      "source": [
        "**⚠️ If you are running this notebook on Colab, restart the session (Runtime > Restart session), to avoid any dependencies errors in the rest of this tutorial.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MclWK2GYnp_"
      },
      "source": [
        "## Hugging Face setup\n",
        "\n",
        "Official [pyannote.audio](https://github.com/pyannote/pyannote-audio) pipelines (i.e. those under the [`pyannote` organization](https://hf.co/pyannote) umbrella) are open-source, but gated. It means that you have to first accept users conditions on their respective Hugging Face page to access the pretrained weights and hyper-parameters.\n",
        "\n",
        "For instance, to load the speaker diarization pipelines used in this tutorial, you have to visit [hf.co/pyannote/speaker-diarization-community-1](https://hf.co/pyannote/speaker-diarization-community-1) and accept the terms.\n",
        "\n",
        "Finally log in using `notebook_login` below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5u7VMb-YnqB"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qggK-7VBYnp8"
      },
      "source": [
        "## How to use `pyannote/speaker-diarization-community-1` ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtZXNtEtOnlZ"
      },
      "source": [
        "Firstly, load the pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5w-IGE1Ov25"
      },
      "outputs": [],
      "source": [
        "from pyannote.audio import Pipeline\n",
        "import torch\n",
        "\n",
        "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-community-1\")\n",
        "\n",
        "# send pipeline to GPU (when available)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "pipeline.to(torch.device(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ctcF5fVQFdg"
      },
      "source": [
        "Apply the pipeline on an audio file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyn8ufT1QNIr"
      },
      "outputs": [],
      "source": [
        "from pyannote.audio.sample import SAMPLE_FILE\n",
        "\n",
        "audio = SAMPLE_FILE[\"audio\"]\n",
        "\n",
        "# check https://github.com/pyannote/pyannote-audio/blob/853b2ab42c3ccd9ec898459d0ad24adc65167b3d/pyannote/audio/core/io.py#L45\n",
        "# to see all accepted input types.\n",
        "outputs = pipeline(audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6-rL-_aU0_Z"
      },
      "source": [
        "We can then visualize `outputs.speaker_diarization`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV3sOnhLWULo"
      },
      "outputs": [],
      "source": [
        "outputs.speaker_diarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qQct_dbTd21"
      },
      "source": [
        "Or visualize the output in a more interactive way using `ipyannote` widget:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_XryMONTcue"
      },
      "outputs": [],
      "source": [
        "from ipyannote import IAnnotation\n",
        "\n",
        "IAnnotation(audio=audio, annotation=outputs.speaker_diarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ajQeskZU5Y0"
      },
      "source": [
        "And even compare with the reference using `ipyannote.Errors`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku7Q6pP4VCbP"
      },
      "outputs": [],
      "source": [
        "from ipyannote.apps import AnnotationDiff\n",
        "\n",
        "reference = SAMPLE_FILE[\"annotation\"]\n",
        "\n",
        "AnnotationDiff(audio=audio, reference=reference.rename_tracks(), hypothesis=outputs.speaker_diarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5KSipqrYiTU"
      },
      "source": [
        "In the visualizer above, the first line shows the reference, the second one displays the pipeline output, and the last line highlights the errors made by the pipeline compared to the reference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0dB68V3bZsO"
      },
      "source": [
        "You might want to get speaker diarization adapted to downstream transcription that does not contains any overlapping speech turns. This can be achieved using `outputs.exclusive_speaker_diarization`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkkYB14uZfcv"
      },
      "outputs": [],
      "source": [
        "IAnnotation(audio=audio, annotation=outputs.exclusive_speaker_diarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hmFmLzFYnp_"
      },
      "source": [
        "## A word about hosted `speaker-diarization-community-1-cloud`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Cz6_-7dipH"
      },
      "source": [
        "A convenient way to get speaker diarization annotation is by using the `pyannote/speaker-diarization-community-1-cloud` pipeline.  \n",
        "It is the same pipeline as the one introduced above, but it runs on the **pyannoteAI server** — so there’s no need to download anything. All you have to do is create an API key on [dashboard.pyannote.ai](https://dashboard.pyannote.ai).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcsxWOU6jrLI"
      },
      "source": [
        "If you are running this notebook on Colab, create an `PYANNOTE_API_KEY` secret using `Secrets` tab on the left, and copy your api key.\n",
        "\n",
        "Then run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e28_iMpLj5Mq"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "token = userdata.get(\"PYANNOTEAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T_QRfhHkCGr"
      },
      "source": [
        "Otherwise, create an environment variable named `PYANNOTEAI_API_KEY` with you api key, and load it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkwM1YMAknUc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "token = os.environ[\"PYANNOTEAI_API_KEY\"] # or simply paste your API key here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGNYZJ1AgZOe"
      },
      "source": [
        "Then you can load the pipeline and process your audio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC05jFO_Ynp_"
      },
      "outputs": [],
      "source": [
        "cloud_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-community-1\", token=token)\n",
        "cloud_outputs = cloud_pipeline(audio)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTIH0rqWmowD"
      },
      "source": [
        "Visualize the speaker diarization outputs in the same way as before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h9JVnrOmubd"
      },
      "outputs": [],
      "source": [
        "IAnnotation(audio=audio, annotation=cloud_outputs.speaker_diarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIBcxzi1m7kV"
      },
      "source": [
        "Want something even more precise? Try the `pyannote/speaker-diarization-precision-2` pipeline:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtH_51m4nXAJ"
      },
      "outputs": [],
      "source": [
        "precision_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-precision-2\", token=token)\n",
        "precision_outputs = precision_pipeline(audio)\n",
        "\n",
        "IAnnotation(audio=audio, annotation=precision_outputs.speaker_diarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxlrTbyPYnqB"
      },
      "source": [
        "## Going further\n",
        "\n",
        "We have only scratched the surface in this introduction.\n",
        "\n",
        "More details can be found in the [`pyannote.audio` Github repository](https://github.com/pyannote/pyannote-audio).\n",
        "\n",
        "You can also visit the [`pyannoteAI`](https://www.pyannote.ai/) website to explore our fastest and most advanced solutions.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pyannote-audio",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
